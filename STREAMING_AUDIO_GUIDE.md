# ğŸ™ï¸ æµå¼éŸ³é¢‘é©±åŠ¨æŒ‡å—

## å¿«é€Ÿå¼€å§‹

æµå¼éŸ³é¢‘åŠŸèƒ½å…è®¸ä½ åœ¨å¤§æ¨¡å‹ TTS è¿”å›éŸ³é¢‘ç‰‡æ®µæ—¶ï¼Œ**å®æ—¶é©±åŠ¨æ•°å­—äººå˜´å½¢åŒæ­¥**ï¼Œæ— éœ€ç­‰å¾…å®Œæ•´éŸ³é¢‘ã€‚

### åŸºç¡€ç”¨æ³•

```javascript
import { DigitalHuman } from './src/index.js';

const avatar = new DigitalHuman({
    container: '#avatar'
});

// å®šä¹‰éŸ³é¢‘æµç”Ÿæˆå™¨
async function* myAudioStream() {
    // ä»ä½ çš„ TTS API è·å–éŸ³é¢‘ç‰‡æ®µ
    const chunks = await fetchAudioChunksFromAPI();

    for (const chunk of chunks) {
        yield chunk; // ArrayBuffer
    }
}

// å¼€å§‹æµå¼æ’­æ”¾
const controller = await avatar.speakStreaming({
    audioStream: myAudioStream(),
    onChunkReceived: (chunk) => {
        console.log('æ”¶åˆ°éŸ³é¢‘:', chunk.byteLength, 'bytes');
    },
    onStreamEnd: () => {
        console.log('æ’­æ”¾å®Œæˆ');
    }
});
```

## æ ¸å¿ƒæ¦‚å¿µ

### 1. AudioBufferSourceNode vs MediaElementAudioSourceNode

**ä¼ ç»Ÿæ¨¡å¼ï¼ˆ`speak()`ï¼‰**ï¼š
- ä½¿ç”¨ `<audio>` å…ƒç´ 
- éœ€è¦å®Œæ•´éŸ³é¢‘æ–‡ä»¶
- ä¸æ”¯æŒåˆ†å—æµå¼æ•°æ®

**æµå¼æ¨¡å¼ï¼ˆ`speakStreaming()`ï¼‰**ï¼š
- ä½¿ç”¨ Web Audio API çš„ AudioBuffer
- æ”¯æŒéŸ³é¢‘ç‰‡æ®µåŠ¨æ€æ·»åŠ 
- å®æ—¶å¤„ç†æµå¼æ•°æ®

### 2. å·¥ä½œæµç¨‹

```
å¤§æ¨¡å‹ TTS â†’ éŸ³é¢‘ç‰‡æ®µ â†’ AudioStreamQueue â†’ AnalyserNode â†’ LipSyncEngine â†’ å˜´å½¢åŒæ­¥
              (chunk)      (æ’é˜Ÿæ’­æ”¾)      (FFTåˆ†æ)    (éŸ³ç´ æ£€æµ‹)   (morph targets)
```

## å®æˆ˜ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šé›†æˆ OpenAI TTS

```javascript
async function speakWithOpenAI(text) {
    async function* openAIStream() {
        const response = await fetch('https://api.openai.com/v1/audio/speech', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${YOUR_KEY}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'tts-1',
                voice: 'alloy',
                input: text,
                response_format: 'mp3'
            })
        });

        const reader = response.body.getReader();

        while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            yield value.buffer;
        }
    }

    await avatar.speakStreaming({
        audioStream: openAIStream()
    });
}
```

### ç¤ºä¾‹ 2ï¼šWebSocket å®æ—¶éŸ³é¢‘

```javascript
// å»ºç«‹ WebSocket è¿æ¥
const ws = new WebSocket('wss://your-tts-server.com');

// åˆ›å»ºæµæ§åˆ¶å™¨
let controller = null;

ws.onopen = async () => {
    // åˆ›å»ºç©ºç”Ÿæˆå™¨ï¼Œæ‰‹åŠ¨æ¨é€
    controller = await avatar.speakStreaming({
        audioStream: async function* () {}
    });

    // å‘é€æ–‡æœ¬
    ws.send(JSON.stringify({ text: 'ä½ å¥½ä¸–ç•Œ' }));
};

// æ¥æ”¶éŸ³é¢‘ç‰‡æ®µ
ws.onmessage = async (event) => {
    if (event.data instanceof Blob) {
        const arrayBuffer = await event.data.arrayBuffer();
        await controller.enqueueAudio(arrayBuffer);
    }
};

ws.onclose = () => {
    if (controller) {
        controller.stop();
    }
};
```

### ç¤ºä¾‹ 3ï¼šæœ¬åœ°æ–‡ä»¶æ¨¡æ‹Ÿæµå¼

```javascript
async function* simulateStream(audioUrl) {
    const response = await fetch(audioUrl);
    const fullAudio = await response.arrayBuffer();

    // å°†å®Œæ•´éŸ³é¢‘åˆ‡åˆ†ä¸ºå°ç‰‡æ®µï¼ˆæ¨¡æ‹Ÿæµå¼è¿”å›ï¼‰
    const chunkSize = 16000; // çº¦ 100ms (16kHz)

    for (let i = 0; i < fullAudio.byteLength; i += chunkSize) {
        const end = Math.min(i + chunkSize, fullAudio.byteLength);
        const chunk = fullAudio.slice(i, end);

        // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await new Promise(resolve => setTimeout(resolve, 100));

        yield chunk;
    }
}

await avatar.speakStreaming({
    audioStream: simulateStream('audio/test.wav')
});
```

## API å‚è€ƒ

### `avatar.speakStreaming(options)`

**å‚æ•°ï¼š**

```typescript
interface StreamingOptions {
    // å¿…å¡«ï¼šéŸ³é¢‘æµç”Ÿæˆå™¨
    audioStream: AsyncGenerator<ArrayBuffer> | (() => AsyncGenerator<ArrayBuffer>);

    // å¯é€‰ï¼šé‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16000ï¼‰
    sampleRate?: number;

    // å¯é€‰ï¼šæ”¶åˆ°ç‰‡æ®µæ—¶çš„å›è°ƒ
    onChunkReceived?: (chunk: ArrayBuffer) => void;

    // å¯é€‰ï¼šæµç»“æŸæ—¶çš„å›è°ƒ
    onStreamEnd?: () => void;
}
```

**è¿”å›å€¼ï¼š**

```typescript
interface StreamController {
    // åœæ­¢æ’­æ”¾
    stop: () => void;

    // æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾
    isPlaying: () => boolean;

    // æ‰‹åŠ¨æ·»åŠ éŸ³é¢‘ç‰‡æ®µ
    enqueueAudio: (chunk: ArrayBuffer) => Promise<void>;
}
```

## éŸ³é¢‘æ ¼å¼

### æ”¯æŒçš„æ ¼å¼

- **WAV**ï¼ˆæ¨èï¼Œæ— éœ€è§£ç ï¼‰
- **MP3**ï¼ˆå¸¸ç”¨ï¼Œè‡ªåŠ¨è§£ç ï¼‰
- **OGG/Opus**ï¼ˆé«˜å‹ç¼©æ¯”ï¼‰
- **AAC/M4A**ï¼ˆApple ç”Ÿæ€ï¼‰

### æ¨èè®¾ç½®

- **é‡‡æ ·ç‡**ï¼š16kHz æˆ– 24kHz
- **æ¯”ç‰¹ç‡**ï¼š64-128 kbps
- **ç‰‡æ®µå¤§å°**ï¼š100-300ms éŸ³é¢‘æ•°æ®
- **å£°é“**ï¼šå•å£°é“ï¼ˆMonoï¼‰

## æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å†²ç­–ç•¥

```javascript
// AudioStreamQueue é»˜è®¤é…ç½®
{
    bufferThreshold: 0.5,      // å½“é˜Ÿåˆ— < 0.5 ç§’æ—¶è§¦å‘ onNeedData
    maxQueueDuration: 10       // æœ€å¤§ç¼“å†² 10 ç§’ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
}
```

### 2. å‡å°‘å»¶è¿Ÿ

- **å‡å°ç‰‡æ®µå¤§å°**ï¼š100ms ç‰‡æ®µæ¯” 500ms æ›´ä½å»¶è¿Ÿ
- **é¢„åŠ è½½**ï¼šæå‰è¯·æ±‚ä¸‹ä¸€ä¸ªç‰‡æ®µ
- **ä½¿ç”¨ WebSocket**ï¼šæ¯” HTTP è½®è¯¢æ›´å®æ—¶

### 3. é”™è¯¯æ¢å¤

```javascript
const controller = await avatar.speakStreaming({
    audioStream: myStream(),
    onChunkReceived: (chunk) => {
        // éªŒè¯éŸ³é¢‘æ•°æ®
        if (chunk.byteLength === 0) {
            console.warn('æ”¶åˆ°ç©ºéŸ³é¢‘ç‰‡æ®µ');
        }
    }
});

// ç›‘å¬é”™è¯¯
avatar.config.onError = (error) => {
    console.error('æ’­æ”¾é”™è¯¯:', error);
    controller.stop();
    // é‡è¯•æˆ–å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼
};
```

## å¸¸è§é—®é¢˜

### Q1: éŸ³é¢‘æ’­æ”¾æœ‰æ‚éŸ³æˆ–å¡é¡¿ï¼Ÿ

**åŸå› **ï¼šéŸ³é¢‘ç‰‡æ®µä¹‹é—´æœ‰é—´éš™æˆ–æ ¼å¼ä¸ä¸€è‡´

**è§£å†³**ï¼š
- ç¡®ä¿æ‰€æœ‰ç‰‡æ®µä½¿ç”¨ç›¸åŒçš„é‡‡æ ·ç‡å’Œæ ¼å¼
- å¢å¤§ `bufferThreshold` ä»¥å¢åŠ ç¼“å†²
- æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ

### Q2: å˜´å½¢ä¸åŒæ­¥ï¼Ÿ

**åŸå› **ï¼šFFT åˆ†æå»¶è¿Ÿæˆ–éŸ³é¢‘è´¨é‡é—®é¢˜

**è§£å†³**ï¼š
- ä½¿ç”¨æ›´é«˜é‡‡æ ·ç‡ï¼ˆâ‰¥ 16kHzï¼‰
- ç¡®ä¿éŸ³é¢‘æ¸…æ™°ï¼Œå‡å°‘èƒŒæ™¯å™ªéŸ³
- è°ƒæ•´ `fftSize`ï¼ˆåœ¨ config ä¸­ï¼‰

### Q3: å†…å­˜å ç”¨è¿‡é«˜ï¼Ÿ

**åŸå› **ï¼šéŸ³é¢‘é˜Ÿåˆ—ç§¯å‹

**è§£å†³**ï¼š
- é™ä½ `maxQueueDuration`
- åŠæ—¶è°ƒç”¨ `stop()` æ¸…ç†èµ„æº
- ä½¿ç”¨å‹ç¼©æ ¼å¼ï¼ˆMP3ï¼‰è€Œé WAV

### Q4: æµè§ˆå™¨å…¼å®¹æ€§ï¼Ÿ

**æ”¯æŒæƒ…å†µ**ï¼š
- âœ… Chrome 89+
- âœ… Firefox 88+
- âœ… Safari 14+
- âœ… Edge 89+

**ä¸æ”¯æŒ**ï¼šIE 11 åŠæ›´æ—©ç‰ˆæœ¬

## è°ƒè¯•æŠ€å·§

### å¯ç”¨è°ƒè¯•æ—¥å¿—

```javascript
const avatar = new DigitalHuman({
    container: '#avatar',
    debug: true  // å¯ç”¨è¯¦ç»†æ—¥å¿—
});
```

### ç›‘æ§éŸ³é¢‘é˜Ÿåˆ—

```javascript
const controller = await avatar.speakStreaming({
    audioStream: myStream(),
    onChunkReceived: (chunk) => {
        console.log(`[${new Date().toISOString()}] æ”¶åˆ° ${chunk.byteLength} bytes`);
    }
});

// æŸ¥çœ‹é˜Ÿåˆ—çŠ¶æ€ï¼ˆå†…éƒ¨å±æ€§ï¼Œä»…è°ƒè¯•ç”¨ï¼‰
console.log('é˜Ÿåˆ—é•¿åº¦:', avatar.audioStreamQueue?.queue.length);
```

### å¯è§†åŒ–é¢‘è°±åˆ†æ

```javascript
// è®¿é—®å†…éƒ¨ analyserï¼ˆä»…è°ƒè¯•ï¼‰
const analyser = avatar.streamAnalyser;
const dataArray = new Uint8Array(analyser.frequencyBinCount);

function visualize() {
    analyser.getByteFrequencyData(dataArray);
    console.log('é¢‘è°±:', Array.from(dataArray.slice(0, 10)));
    requestAnimationFrame(visualize);
}

visualize();
```

## æœ€ä½³å®è·µ

1. **æ€»æ˜¯å¤„ç†é”™è¯¯**ï¼šæ·»åŠ  `onError` å›è°ƒ
2. **æ¸…ç†èµ„æº**ï¼šä¸å†ä½¿ç”¨æ—¶è°ƒç”¨ `destroy()`
3. **æµ‹è¯•ç½‘ç»œæ¡ä»¶**ï¼šåœ¨æ…¢ç½‘ç»œä¸‹æµ‹è¯•ç¼“å†²ç­–ç•¥
4. **ç›‘æ§æ€§èƒ½**ï¼šä½¿ç”¨ Chrome DevTools çš„ Performance é¢æ¿
5. **æ¸è¿›å¢å¼º**ï¼šæä¾›ä¼ ç»Ÿæ¨¡å¼ä½œä¸ºåå¤‡æ–¹æ¡ˆ

```javascript
async function speak(audio) {
    // å°è¯•æµå¼æ¨¡å¼
    if (isStreamingSupported()) {
        try {
            await avatar.speakStreaming({ audioStream: audio });
        } catch (error) {
            console.warn('æµå¼æ¨¡å¼å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼');
            await avatar.speak(audio);
        }
    } else {
        // å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼
        await avatar.speak(audio);
    }
}

function isStreamingSupported() {
    return 'AudioContext' in window &&
           'createBufferSource' in AudioContext.prototype;
}
```

## è¿›ä¸€æ­¥é˜…è¯»

- [Web Audio API æ–‡æ¡£](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [AudioBuffer è¯¦è§£](https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer)
- [Async Generators](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function*)
- [å®Œæ•´ç¤ºä¾‹](./examples/streaming-audio.html)

---

**æœ‰é—®é¢˜ï¼Ÿ** è¯·åœ¨ [GitHub Issues](https://github.com/zizaijiyihu/digital-human-component/issues) æå‡ºã€‚
